{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e90a4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "hsb2 = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\Vaishnavi\\\\Auto\\\\DriverData1.csv\")\n",
    "\n",
    "hsb2[\"Gap\"] = hsb2[\"Gap\"].astype('int64')\n",
    "hsb2[\"RelativeSpeed\"] = hsb2[\"RelativeSpeed\"].astype('int64')\n",
    "hsb2[\"TW\"] = hsb2[\"TW\"].astype('category')\n",
    "hsb2['Choice']=hsb2['Choice']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "64feb2bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modified DataFrame:\n",
      "        ID  SubVehID  Choice  Gap  RelativeSpeed TW  Observed_Choice\n",
      "0        1         9       2   12              0  0                0\n",
      "1        1         9       2   12              0  0                1\n",
      "2        1         9       2   12              0  0                0\n",
      "3        2        13       1   16              2  1                1\n",
      "4        2        13       1   16              2  1                0\n",
      "...    ...       ...     ...  ...            ... ..              ...\n",
      "7195  2399      3002       3   15              3  1                0\n",
      "7196  2399      3002       3   15              3  1                1\n",
      "7197  2400      3002       2   15              4  1                0\n",
      "7198  2400      3002       2   15              4  1                1\n",
      "7199  2400      3002       2   15              4  1                0\n",
      "\n",
      "[7200 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "df=hsb2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Repeat each row 3 times (including the original)\n",
    "repeated_df = df.loc[df.index.repeat(3)].reset_index(drop=True)\n",
    "\n",
    "# Add the new column 'D' with 0s\n",
    "repeated_df['Observed_Choice'] = 0\n",
    "\n",
    "# Set the value to 1 at the specified indices\n",
    "for original_index in df.index:\n",
    "    repeated_indices = repeated_df.index[original_index*3 : original_index*3 + 3]\n",
    "    repeated_df.loc[repeated_indices[df.loc[original_index, 'Choice']-1], 'Observed_Choice'] = 1\n",
    "\n",
    "# Print the modified DataFrame\n",
    "print(\"\\nModified DataFrame:\")\n",
    "print(repeated_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "87bfc2b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.27643114 -0.61920665 -2.72269309]\n",
      " [ 2.1531517  -0.40006169 -0.67794147]\n",
      " [ 0.05752646 -0.7151739  -1.31920894]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected a 1D array, got an array with shape (7200, 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3652\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3653\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\_libs\\index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'exp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4110\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4109\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 4110\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3654\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[1;32m-> 3655\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3656\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3657\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3658\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3659\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'exp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(theta)\n\u001b[0;32m      5\u001b[0m a \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(np\u001b[38;5;241m.\u001b[39mdot(X, theta))  \u001b[38;5;66;03m# Compute 'a' using the dot product\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m repeated_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m a  \u001b[38;5;66;03m# Assign 'a' directly as 'exp' column\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Calculate softmax grouped by 'ID'\u001b[39;00m\n\u001b[0;32m      9\u001b[0m softmax_by_category \u001b[38;5;241m=\u001b[39m repeated_df\u001b[38;5;241m.\u001b[39mgroupby(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mID\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mexp\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mtransform(\u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39mexp(x) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mexp(x)))\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:3950\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   3947\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   3948\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   3949\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 3950\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item(key, value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4156\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4153\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(existing_piece, DataFrame):\n\u001b[0;32m   4154\u001b[0m             value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mtile(value, (\u001b[38;5;28mlen\u001b[39m(existing_piece\u001b[38;5;241m.\u001b[39mcolumns), \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m-> 4156\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_item_mgr(key, value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[0m, in \u001b[0;36mDataFrame._set_item_mgr\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4110\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m   4112\u001b[0m     \u001b[38;5;66;03m# This item wasn't present, just insert at end\u001b[39;00m\n\u001b[1;32m-> 4113\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info_axis), key, value)\n\u001b[0;32m   4114\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4115\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iset_item_mgr(loc, value)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1403\u001b[0m, in \u001b[0;36mBlockManager.insert\u001b[1;34m(self, loc, item, value)\u001b[0m\n\u001b[0;32m   1401\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39mT\n\u001b[0;32m   1402\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(value) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m-> 1403\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m   1404\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected a 1D array, got an array with shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;241m.\u001b[39mT\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1405\u001b[0m         )\n\u001b[0;32m   1406\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1407\u001b[0m     value \u001b[38;5;241m=\u001b[39m ensure_block_shape(value, ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mndim)\n",
      "\u001b[1;31mValueError\u001b[0m: Expected a 1D array, got an array with shape (7200, 3)"
     ]
    }
   ],
   "source": [
    "num_classes = 3  # Assuming 3 classes\n",
    "num_features = X.shape[1]\n",
    "theta = np.random.randn(num_features, num_classes)\n",
    "print(theta)\n",
    "a = np.exp(np.dot(X, theta))  # Compute 'a' using the dot product\n",
    "\n",
    "repeated_df['exp'] = a  # Assign 'a' directly as 'exp' column\n",
    "# Calculate softmax grouped by 'ID'\n",
    "softmax_by_category = repeated_df.groupby('ID')['exp'].transform(lambda x: np.exp(x) / np.sum(np.exp(x)))\n",
    "\n",
    "# Assign 'a' and 'softmax' columns to repeated_df\n",
    "\n",
    "repeated_df['softmax'] = softmax_by_category  # Assign calculated softmax values\n",
    "\n",
    "print(repeated_df.head())  # Print first few rows to verify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4712be8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "theta = np.array([\n",
    "    [ 1.27643114, -0.61920665, -2.72269309],\n",
    "    [ 2.1531517 , -0.40006169, -0.67794147],\n",
    "    [ 0.05752646, -0.7151739 , -1.31920894]\n",
    "])\n",
    "\n",
    "X = np.array([\n",
    "    [10, 0, 0],\n",
    "    [10, 0, 0],\n",
    "    [10, 0, 0],\n",
    "    [1, 2, 1],\n",
    "    [1, 2, 1]\n",
    "])\n",
    "[[ 12.7643114   -6.1920665   -2.72269309]\n",
    " [ 12.7643114   -6.1920665   -2.72269309]\n",
    " [ 12.7643114   -6.1920665   -2.72269309]\n",
    " [  5.4871093   -2.85151224  -4.7198435 ]\n",
    " [  5.4871093   -2.85151224  -4.7198435 ]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62bee8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "953d08ab",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b702f306",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Gap  RelativeSpeed TW\n",
      "0      12              0  0\n",
      "1      12              0  0\n",
      "2      12              0  0\n",
      "3      16              2  1\n",
      "4      16              2  1\n",
      "...   ...            ... ..\n",
      "7195   15              3  1\n",
      "7196   15              3  1\n",
      "7197   15              4  1\n",
      "7198   15              4  1\n",
      "7199   15              4  1\n",
      "\n",
      "[7200 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98aaf4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "repeated_df.to_csv(\"df.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b1527ee0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SubVehID</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Gap</th>\n",
       "      <th>RelativeSpeed</th>\n",
       "      <th>TW</th>\n",
       "      <th>Observed_Choice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SubVehID  Choice  Gap  RelativeSpeed TW  Observed_Choice\n",
       "0   1         9       2   12              0  0                0\n",
       "1   1         9       2   12              0  0                1\n",
       "2   1         9       2   12              0  0                0\n",
       "3   2        13       1   16              2  1                1\n",
       "4   2        13       1   16              2  1                0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb3 = repeated_df\n",
    "hsb3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98220763",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hsb3['Observed_Choice']\n",
    "X = hsb3.drop(['ID','SubVehID','Choice','Observed_Choice'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4cc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becfeb32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Compute the softmax of each row of the input array z.\n",
    "    \n",
    "    Parameters:\n",
    "    z (ndarray): Input array of shape (n, k) where n is the number of samples and k is the number of classes.\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: Output array of the same shape as z where each row is the softmax of the corresponding row of z.\n",
    "    \"\"\"\n",
    "      # Subtract max for numerical stability\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7806b561",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ba6dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6a3880",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47859cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a11e72a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ecb23e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098d875b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970ca486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29f7dfef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35d112d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c838ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "765e4439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [-0.34657607]\n",
      "Coefficients: [[ 1.84833410e-07 -2.90458183e-08 -4.42208346e-07]]\n",
      " \n",
      "Rho-squared: -8.815170815523743e-14\n",
      "Chi-square statistic: -8.076312951743603e-10\n",
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import log_loss\n",
    "# Create a multinomial logistic regression model\n",
    "\n",
    "\n",
    "model =LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', \n",
    "                           C=1.0, max_iter=1000000)\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "print(\"Intercept:\",model.intercept_)\n",
    "print(\"Coefficients:\",model.coef_)\n",
    "\n",
    "\n",
    "\n",
    "# Get the log-likelihood of the fitted model\n",
    "y_prob = model.predict_proba(X)\n",
    "LL_model = -log_loss(y, y_prob, normalize=False)\n",
    "\n",
    "# Fit the null model (only an intercept)\n",
    "null_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', \n",
    "                                C=1.0, max_iter=1000000, fit_intercept=True)\n",
    "X_null = np.ones((X.shape[0], 1))  # Only intercept\n",
    "null_model.fit(X_null, y)\n",
    "\n",
    "# Get the log-likelihood of the null model\n",
    "y_null_prob = null_model.predict_proba(X_null)\n",
    "LL_null = -log_loss(y, y_null_prob, normalize=False)\n",
    "\n",
    "\n",
    "chi_square_stat = 2 * (LL_model - LL_null)\n",
    "df_model = X.shape[1] * (len(np.unique(y)) - 1) \n",
    "df_null = len(np.unique(y)) - 1  # Number of intercepts in the null model\n",
    "df_diff = df_model - df_null\n",
    "p_value = stats.chi2.sf(chi_square_stat, df_diff)\n",
    "rho_squared = 1 - (LL_model / LL_null)\n",
    "print(\" \")\n",
    "print(\"Rho-squared:\", rho_squared)\n",
    "print(\"Chi-square statistic:\", chi_square_stat)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6f10615",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = []\n",
    "# Initialize an empty list to store predicted probabilities\n",
    "for i in range(len(hsb2.ID)):\n",
    "    row = X.iloc[i:i+1, :]  # Select a single row from the DataFrame\n",
    "    # Predict a multinomial probability distribution\n",
    "    yhat = model.predict(row)\n",
    "    # Summarize the predicted probabilities and append to the list\n",
    "    c.append(yhat[0])\n",
    "    \n",
    "\n",
    "hsb2['Predicted'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9994efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a0a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "20864e4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (7200,) (7200,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m num_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     29\u001b[0m beta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(num_features, num_classes)\n\u001b[1;32m---> 31\u001b[0m ll \u001b[38;5;241m=\u001b[39m log_likelihood(X, y, beta)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLog Likelihood:\u001b[39m\u001b[38;5;124m\"\u001b[39m, ll)\n",
      "Cell \u001b[1;32mIn[20], line 19\u001b[0m, in \u001b[0;36mlog_likelihood\u001b[1;34m(X, y, beta)\u001b[0m\n\u001b[0;32m     16\u001b[0m eXB \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(W)\n\u001b[0;32m     17\u001b[0m eXB \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m eXB\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m---> 19\u001b[0m log_likelihood_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(y \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(eXB))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_likelihood_value\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:202\u001b[0m, in \u001b[0;36mOpsMixin.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__mul__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arith_method(other, operator\u001b[38;5;241m.\u001b[39mmul)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6112\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6111\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m-> 6112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base\u001b[38;5;241m.\u001b[39mIndexOpsMixin\u001b[38;5;241m.\u001b[39m_arith_method(\u001b[38;5;28mself\u001b[39m, other, op)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:1348\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1345\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1348\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:232\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    168\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(left, right)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:128\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    125\u001b[0m     _store_test_result(result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     result \u001b[38;5;241m=\u001b[39m _evaluate_standard(op, op_str, a, b)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (7200,) (7200,3) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_likelihood(X, y, beta):\n",
    "    \"\"\"\n",
    "    Calculate the log likelihood for multinomial logistic regression.\n",
    "    \n",
    "    Args:\n",
    "        X (numpy.ndarray): Design matrix (shape: N x M), where N is the number of samples and M is the number of features.\n",
    "        y (numpy.ndarray): Target labels (shape: N x 1), where each label corresponds to a class (0, 1, ..., K-1).\n",
    "        beta (numpy.ndarray): Model coefficients (shape: M x K), where K is the number of classes.\n",
    "    \n",
    "    Returns:\n",
    "        float: Log likelihood value.\n",
    "    \"\"\"\n",
    "    W = np.dot(X, beta)\n",
    "    eXB = np.exp(W)\n",
    "    eXB /= eXB.sum(axis=1)[:, None]\n",
    "    \n",
    "    log_likelihood_value = np.sum(y * np.log(eXB))\n",
    "    return log_likelihood_value\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have X (design matrix), y (target labels), and beta (model coefficients)\n",
    "# log_likelihood_value = log_likelihood(X, y, beta)\n",
    "# print(f\"Log Likelihood: {log_likelihood_value:.4f}\")\n",
    "# Initialize theta with correct shape\n",
    "num_classes = 3  # Assuming 3 classes\n",
    "num_features = X.shape[1]\n",
    "beta = np.random.randn(num_features, num_classes)\n",
    "\n",
    "ll = log_likelihood(X, y, beta)\n",
    "print(\"Log Likelihood:\", ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ebe45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "39bd4eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood: -21373.226860399085\n",
      "Null Log Likelihood: -4720.558359658337\n",
      " \n",
      "Rho-squared: -3.5276904196447703\n",
      "Chi-square statistic: -33305.337001481494\n",
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Compute the softmax of each row of the input array z.\n",
    "    \n",
    "    Parameters:\n",
    "    z (ndarray): Input array of shape (n, k) where n is the number of samples and k is the number of classes.\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: Output array of the same shape as z where each row is the softmax of the corresponding row of z.\n",
    "    \"\"\"\n",
    "      # Subtract max for numerical stability\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "\n",
    "def log_likelihood_multinomial_logistic(X, y, theta):\n",
    "    \"\"\"\n",
    "    Calculate the log likelihood of the data given a multinomial logistic regression model.\n",
    "    \n",
    "    Parameters:\n",
    "    X (ndarray): Input feature matrix of shape (n, d).\n",
    "    y (ndarray): True class labels of shape (n,).\n",
    "    theta (ndarray): Model parameters of shape (d, k).\n",
    "    \n",
    "    Returns:\n",
    "    float: Log likelihood value.\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    k = theta.shape[1]\n",
    "    \n",
    "    # Compute the linear combination\n",
    "    linear_combination = np.dot(X, theta)\n",
    "    \n",
    "    # Compute the softmax probabilities\n",
    "    probabilities = softmax(linear_combination)\n",
    "    \n",
    "    # Create a one-hot encoded matrix of the true labels\n",
    "    y_one_hot = np.zeros((n, k))\n",
    "    y_one_hot[np.arange(n), y] = 1\n",
    "    \n",
    "    # Compute the log likelihood\n",
    "    log_likelihood = np.sum(y_one_hot * np.log(probabilities))\n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "# Initialize theta with correct shape\n",
    "num_classes = 3  # Assuming 3 classes\n",
    "num_features = X.shape[1]\n",
    "theta = np.random.randn(num_features, num_classes)\n",
    "\n",
    "X_null = np.ones((X.shape[0], 3))  # Only intercept\n",
    "\n",
    "ll = log_likelihood_multinomial_logistic(X, y, theta)\n",
    "print(\"Log Likelihood:\", ll)\n",
    "\n",
    "null_ll = log_likelihood_multinomial_logistic(X_null, y, theta)\n",
    "print(\"Null Log Likelihood:\", null_ll)\n",
    "\n",
    "chi_square_stat = 2 * (ll - null_ll)\n",
    "\n",
    "df_model = X.shape[1] * (len(np.unique(y)) - 1) \n",
    "df_null = len(np.unique(y)) - 1  # Number of intercepts in the null model\n",
    "df_diff = df_model - df_null\n",
    "p_value = stats.chi2.sf(chi_square_stat, df_diff)\n",
    "rho_squared = 1 - (ll / null_ll)\n",
    "print(\" \")\n",
    "print(\"Rho-squared:\", rho_squared)\n",
    "print(\"Chi-square statistic:\", chi_square_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a1deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc5b0bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood: -166121.18823852536\n",
      "Null Log Likelihood: -10433.913614817387\n",
      " \n",
      "Rho-squared: -14.92127310720818\n",
      "Chi-square statistic: -311374.5492474159\n",
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def softmax(logits):\n",
    "    \"\"\"\n",
    "    Compute the softmax for a set of logits.\n",
    "\n",
    "    Parameters:\n",
    "    logits (np.ndarray): An array of logits with shape (n_samples, n_classes).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: An array of probabilities with the same shape as logits.\n",
    "    \"\"\"\n",
    "    # Subtract the max logits to prevent overflow issues\n",
    "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    # Calculate softmax by dividing the exponentiated logits by the sum of exponentiated logits for each sample\n",
    "    probabilities = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "    return probabilities\n",
    "\n",
    "def log_likelihood_multinomial_logistic(X, y, theta):\n",
    "    \"\"\"\n",
    "    Calculate the log likelihood of the data given a multinomial logistic regression model.\n",
    "    \n",
    "    Parameters:\n",
    "    X (ndarray): Input feature matrix of shape (n, d).\n",
    "    y (ndarray): True class labels of shape (n,).\n",
    "    theta (ndarray): Model parameters of shape (d, k).\n",
    "    \n",
    "    Returns:\n",
    "    float: Log likelihood value.\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    k = theta.shape[1]\n",
    "    \n",
    "    # Compute the linear combination\n",
    "    linear_combination = np.dot(X, theta)\n",
    "    \n",
    "    # Compute the softmax probabilities\n",
    "    probabilities = softmax(linear_combination)\n",
    "    \n",
    "    # Create a one-hot encoded matrix of the true labels\n",
    "    y_one_hot = np.zeros((n, k))\n",
    "    y_one_hot[np.arange(n), y] = 1\n",
    "    \n",
    "    # Compute the log likelihood\n",
    "    log_likelihood = np.sum(y_one_hot * np.log(probabilities))\n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "# Initialize theta with correct shape\n",
    "num_classes = 3  # Assuming 3 classes\n",
    "num_features = X.shape[1]\n",
    "theta = np.random.randn(num_features, num_classes)\n",
    "\n",
    "X_null = np.ones((X.shape[0], 3))  # Only intercept\n",
    "\n",
    "ll = log_likelihood_multinomial_logistic(X, y, theta)\n",
    "print(\"Log Likelihood:\", ll)\n",
    "\n",
    "null_ll = log_likelihood_multinomial_logistic(X_null, y, theta)\n",
    "print(\"Null Log Likelihood:\", null_ll)\n",
    "\n",
    "chi_square_stat = 2 * (ll - null_ll)\n",
    "\n",
    "df_model = X.shape[1] * (len(np.unique(y)) - 1) \n",
    "df_null = len(np.unique(y)) - 1  # Number of intercepts in the null model\n",
    "df_diff = df_model - df_null\n",
    "p_value = stats.chi2.sf(chi_square_stat, df_diff)\n",
    "rho_squared = 1 - (ll / null_ll)\n",
    "print(\" \")\n",
    "print(\"Rho-squared:\", rho_squared)\n",
    "print(\"Chi-square statistic:\", chi_square_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e48560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1748d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945d946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b80b4cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept and Coefficients:\n",
      "[[ 2.14666262 -0.12960308 -0.20794964  0.15761092]\n",
      " [-0.45839896 -0.0203722  -0.07868068  0.05502989]\n",
      " [-1.68828305  0.14947839  0.28660041 -0.21266022]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Define the softmax function\n",
    "def softmax(z):\n",
    "\n",
    "\n",
    "# Define the log-likelihood function\n",
    "def log_likelihood(params, X, y, num_classes):\n",
    "    num_samples, num_features = X.shape\n",
    "    # Reshape the parameter array into a coefficient matrix\n",
    "    beta = params.reshape(num_classes, num_features + 1)\n",
    "    # Add a column of ones for the intercept term\n",
    "    X_intercept = np.hstack([np.ones((num_samples, 1)), X])\n",
    "    \n",
    "    # Compute the linear combination\n",
    "    logits = np.dot(X_intercept, beta.T)\n",
    "    # Compute the probabilities using the softmax function\n",
    "    probabilities = softmax(logits)\n",
    "    # Compute the log-likelihood\n",
    "    log_likelihood = np.sum(np.log(probabilities[np.arange(num_samples), y]))\n",
    "    return -log_likelihood  # Return the negative log-likelihood for minimization\n",
    "\n",
    "# Define a function to fit the model\n",
    "def fit_multinomial_logistic_regression(X, y, num_classes, max_iter=1000000):\n",
    "    num_samples, num_features = X.shape\n",
    "    # Initialize parameters\n",
    "    initial_params = np.zeros((num_classes, num_features + 1)).ravel()\n",
    "    # Optimize the log-likelihood function\n",
    "    result = minimize(log_likelihood, initial_params, args=(X, y, num_classes),\n",
    "                      method='L-BFGS-B', options={'maxiter': max_iter})\n",
    "    # Reshape the result into the coefficient matrix\n",
    "    beta = result.x.reshape(num_classes, num_features + 1)\n",
    "    return beta\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "# Subtract 1 from y to ensure class labels start from 0\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "beta = fit_multinomial_logistic_regression(X, y, num_classes)\n",
    "\n",
    "\n",
    "print(\"Intercept and Coefficients:\")\n",
    "print(beta)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d579a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict probabilities\n",
    "def predict_probabilities(X, beta):\n",
    "    X_intercept = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "    logits = np.dot(X_intercept, beta.T)\n",
    "    probabilities = softmax(logits)\n",
    "    return probabilities\n",
    "\n",
    "# Predict probabilities and class labels\n",
    "c = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(hsb2)):\n",
    "    row = X.iloc[i:i+1, :]  # Select a single row from the DataFrame\n",
    "    # Predict a multinomial probability distribution\n",
    "    phat = predict_probabilities(row, beta)\n",
    "    # Summarize the predicted probabilities and append to the list\n",
    "    c.append(phat[0])\n",
    "    # Determine the predicted class label (the one with the highest probability)\n",
    "    y_pred.append(np.argmax(phat))\n",
    "hsb2['Predicted_1'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa99a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58b6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49846f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db50098f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.863698\n",
      "         Iterations 6\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                 Choice   No. Observations:                 2400\n",
      "Model:                        MNLogit   Df Residuals:                     2392\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Thu, 13 Jun 2024   Pseudo R-squ.:                  0.1224\n",
      "Time:                        12:00:50   Log-Likelihood:                -2072.9\n",
      "converged:                       True   LL-Null:                       -2361.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.331e-121\n",
      "=================================================================================\n",
      "     Choice=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -2.6055      0.604     -4.311      0.000      -3.790      -1.421\n",
      "Gap               0.1093      0.040      2.726      0.006       0.031       0.188\n",
      "RelativeSpeed     0.1293      0.043      2.985      0.003       0.044       0.214\n",
      "TW               -0.1025      0.137     -0.747      0.455      -0.371       0.166\n",
      "---------------------------------------------------------------------------------\n",
      "     Choice=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -3.8349      0.469     -8.174      0.000      -4.754      -2.915\n",
      "Gap               0.2791      0.031      9.035      0.000       0.219       0.340\n",
      "RelativeSpeed     0.4945      0.036     13.565      0.000       0.423       0.566\n",
      "TW               -0.3703      0.104     -3.567      0.000      -0.574      -0.167\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fitting the MNLogit model\n",
    "X1 = sm.add_constant(X)\n",
    "\n",
    "model = sm.MNLogit(y, X1)\n",
    "result = model.fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaefebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "pred_probs = result.predict(X1)\n",
    "\n",
    "# Predict the class with the highest probability\n",
    "y_pred = np.argmax(pred_probs.values, axis=1)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "hsb2['Predicted_Class'] = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99f09aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsb2.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4cd66aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "n, d = X.shape\n",
    "k = theta.shape[1]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create a one-hot encoded matrix of the true labels\n",
    "y_one_hot = np.zeros((n, k))\n",
    "y_one_hot[np.arange(n), y] = 1\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6635d468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  int64\n",
       "SubVehID            int64\n",
       "Choice              int64\n",
       "Gap                 int64\n",
       "RelativeSpeed       int64\n",
       "TW               category\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54489d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
