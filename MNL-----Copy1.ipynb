{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b292bb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f979e4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "98220763",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsb2 = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\Vaishnavi\\\\Auto\\\\DriverData1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0ad8134f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SubVehID</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Gap</th>\n",
       "      <th>RelativeSpeed</th>\n",
       "      <th>TW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>12.0530</td>\n",
       "      <td>-0.927</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>16.3285</td>\n",
       "      <td>2.448</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>15.6910</td>\n",
       "      <td>1.845</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0280</td>\n",
       "      <td>0.999</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>2</td>\n",
       "      <td>12.9030</td>\n",
       "      <td>0.144</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SubVehID  Choice      Gap  RelativeSpeed  TW\n",
       "0   1         9       2  12.0530         -0.927   0\n",
       "1   2        13       1  16.3285          2.448   1\n",
       "2   3        13       3  15.6910          1.845   1\n",
       "3   4        13       1  15.0280          0.999   1\n",
       "4   5        36       2  12.9030          0.144   0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "464badf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                 int64\n",
       "SubVehID           int64\n",
       "Choice             int64\n",
       "Gap              float64\n",
       "RelativeSpeed    float64\n",
       "TW                 int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86c0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsb2[\"Gap\"] = hsb2[\"Gap\"].astype('int64')\n",
    "hsb2[\"RelativeSpeed\"] = hsb2[\"RelativeSpeed\"].astype('int64')\n",
    "hsb2[\"TW\"] = hsb2[\"TW\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822346ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsb2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsb3 = hsb2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b420e6b1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'hsb3' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m hsb3\u001b[38;5;241m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'hsb3' is not defined"
     ]
    }
   ],
   "source": [
    "hsb3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e77527c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffc4cc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hsb3['Choice']\n",
    "X = hsb3.drop(['ID','SubVehID','Choice'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "bce7e50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Intercept       Gap  RelativeSpeed        TW\n",
      "2  -1.775865 -0.011993      -0.082317  0.030870\n",
      "1   2.821543 -0.229066      -0.380298  0.281062\n",
      "3  -3.726033  0.249797       0.459104 -0.343074\n",
      "Chi-square statistic: 547.5862685536517\n",
      "Degrees of freedom: 3.0\n",
      "p-value: 2.3179810563816417e-118\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit separate binary logistic regression models for each category against all others\n",
    "unique_choices = y.unique()\n",
    "coefficients = {}\n",
    "\n",
    "for choice in unique_choices:\n",
    "    y_binary = (y == choice).astype(int)\n",
    "    model = sm.Logit(y_binary, X)\n",
    "    result = model.fit(disp=False)\n",
    "    coefficients[choice] = result.params\n",
    "\n",
    "# Combine coefficients into a single DataFrame\n",
    "coefficients_df = pd.DataFrame(coefficients).T\n",
    "coefficients_df.columns = ['Intercept'] + list(X.columns[1:])\n",
    "\n",
    "print(coefficients_df)\n",
    "\n",
    "X_null = sm.add_constant(pd.DataFrame({'Intercept': [1] * len(y)}))\n",
    "null_coefficients = {}\n",
    "\n",
    "for choice in unique_choices:\n",
    "    y_null_binary = (y == choice).astype(int)\n",
    "    null_model = sm.Logit(y_null_binary, X_null)\n",
    "    null_result = null_model.fit(disp=False)\n",
    "    null_coefficients[choice] = null_result.params\n",
    "\n",
    "# Combine coefficients into a single DataFrame\n",
    "coefficients_df = pd.DataFrame(null_coefficients).T\n",
    "coefficients_df.columns = ['Intercept'] + list(X_null.columns[1:])\n",
    "\n",
    "LL_model = result.llf  # Log-likelihood of the fitted model\n",
    "LL_null = null_result.llf  # Log-likelihood of the null model\n",
    "chi_square_stat = 2 * (LL_model - LL_null)\n",
    "df_diff = result.df_model - null_result.df_model\n",
    "p_value = stats.chi2.sf(chi_square_stat, df_diff)\n",
    "print(\"Chi-square statistic:\", chi_square_stat)\n",
    "print(\"Degrees of freedom:\", df_diff)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da66440b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Intercept       Gap  RelativeSpeed        TW\n",
      "2  -1.775865 -0.011993      -0.082317  0.030870\n",
      "1   2.821543 -0.229066      -0.380298  0.281062\n",
      "3  -3.726033  0.249797       0.459104 -0.343074\n",
      "McFadden's pseudo-R^2: 0.16519589484174013\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fit separate binary logistic regression models for each category against all others\n",
    "unique_choices = y.unique()\n",
    "coefficients = {}\n",
    "\n",
    "for choice in unique_choices:\n",
    "    y_binary = (y == choice).astype(int)\n",
    "    model = sm.Logit(y_binary, X)\n",
    "    result = model.fit(disp=False)\n",
    "    coefficients[choice] = result.params\n",
    "\n",
    "# Combine coefficients into a single DataFrame\n",
    "coefficients_df = pd.DataFrame(coefficients).T\n",
    "coefficients_df.columns = ['Intercept'] + list(X.columns[1:])\n",
    "\n",
    "print(coefficients_df)\n",
    "\n",
    "X_null = sm.add_constant(pd.DataFrame({'Intercept': [1] * len(y)}))\n",
    "null_coefficients = {}\n",
    "\n",
    "for choice in unique_choices:\n",
    "    y_null_binary = (y == choice).astype(int)\n",
    "    null_model = sm.Logit(y_null_binary, X_null)\n",
    "    null_result = null_model.fit(disp=False)\n",
    "    null_coefficients[choice] = null_result.params\n",
    "\n",
    "# Combine coefficients into a single DataFrame\n",
    "coefficients_df = pd.DataFrame(null_coefficients).T\n",
    "coefficients_df.columns = ['Intercept'] + list(X_null.columns[1:])\n",
    "\n",
    "# Calculate McFadden's pseudo-R^2\n",
    "LL_model = result.llf  # Log-likelihood of the fitted model\n",
    "LL_null = null_result.llf  # Log-likelihood of the null model\n",
    "rho_squared = 1 - (LL_model / LL_null)\n",
    "\n",
    "# Print the result\n",
    "print(\"McFadden's pseudo-R^2:\", rho_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "66d1f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.64875\n",
      "[ 2.14744897 -0.45742293 -1.69002604]\n",
      "[[-0.12946688 -0.20774494  0.15692087]\n",
      " [-0.02023765 -0.07849998  0.0538605 ]\n",
      " [ 0.14970453  0.28624493 -0.21078137]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "\n",
    "# Create a multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Predict the class labels for the same data\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(model.intercept_)\n",
    "print(model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "aeb98b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rho-squared: 0.12235023609532403\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "# Create a multinomial logistic regression model\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', \n",
    "                           C=1.0, max_iter=1000000)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "\n",
    "# Get the log-likelihood of the fitted model\n",
    "y_prob = model.predict_proba(X)\n",
    "LL_model = -log_loss(y, y_prob, normalize=False)\n",
    "\n",
    "# Fit the null model (only an intercept)\n",
    "null_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', \n",
    "                                C=1.0, max_iter=1000000, fit_intercept=True)\n",
    "X_null = np.ones((X.shape[0], 1))  # Only intercept\n",
    "null_model.fit(X_null, y)\n",
    "\n",
    "# Get the log-likelihood of the null model\n",
    "y_null_prob = null_model.predict_proba(X_null)\n",
    "LL_null = -log_loss(y, y_null_prob, normalize=False)\n",
    "\n",
    "# Compute rho-squared\n",
    "rho_squared = 1 - (LL_model / LL_null)\n",
    "print(\"Rho-squared:\", rho_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "27f0e631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation Score: 0.63375\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_scores = cross_val_score(model, X, y, cv=5, scoring='accuracy')\n",
    "\n",
    "# Compute mean of cross-validation scores\n",
    "mean_cv_score = cv_scores.mean()\n",
    "print(\"Mean Cross-Validation Score:\", mean_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60f34a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.647 (0.025)\n"
     ]
    }
   ],
   "source": [
    "# define the multinomial logistic regression model with a default penalty\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', \n",
    "                           C=1.0, max_iter = 1000000)\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report the model performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "21ec1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "16d283b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 2.14744897 -0.45742293 -1.69002604]\n",
      "[[-0.12946688 -0.20774494  0.15692087]\n",
      " [-0.02023765 -0.07849998  0.0538605 ]\n",
      " [ 0.14970453  0.28624493 -0.21078137]]\n"
     ]
    }
   ],
   "source": [
    "print(result.intercept_)\n",
    "print(result.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "405144eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(zip(X.columns, np.transpose(result.coef_.tolist()[0])), \n",
    "                       columns=['features', 'coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f91d55f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        features      coef\n",
      "0            Gap -0.129467\n",
      "1  RelativeSpeed -0.207745\n",
      "2             TW  0.156921\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e63f304",
   "metadata": {},
   "outputs": [],
   "source": [
    "p1= []\n",
    "p2 = []\n",
    "p3 = []\n",
    "# Initialize an empty list to store predicted probabilities\n",
    "for i in range(len(hsb2.ID)):\n",
    "    row = X.iloc[i:i+1, :]  # Select a single row from the DataFrame\n",
    "    # Predict a multinomial probability distribution\n",
    "    yhat = model.predict_proba(row)\n",
    "    # Summarize the predicted probabilities and append to the list\n",
    "    p1.append(yhat[0][0])\n",
    "    p2.append(yhat[0][1])\n",
    "    p3.append(yhat[0][2])\n",
    "\n",
    "hsb2['P1'] = p1\n",
    "hsb2['P2'] = p2\n",
    "hsb2['P3'] = p3\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "45b5bbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 3\n"
     ]
    }
   ],
   "source": [
    "# predict the class label\n",
    "yhat = model.predict(row)\n",
    "# summarize the predicted class\n",
    "print('Predicted Class: %d' % yhat[0])\n",
    "\n",
    "c = []\n",
    "# Initialize an empty list to store predicted probabilities\n",
    "for i in range(len(hsb2.ID)):\n",
    "    row = X.iloc[i:i+1, :]  # Select a single row from the DataFrame\n",
    "    # Predict a multinomial probability distribution\n",
    "    yhat = model.predict(row)\n",
    "    # Summarize the predicted probabilities and append to the list\n",
    "    c.append(yhat[0])\n",
    "    \n",
    "\n",
    "hsb2['Predicted'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "863975fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        ID  Choice  Gap  RelativeSpeed TW        P1        P2        P3  \\\n",
      "0        1       2   12              0  0  0.529563  0.145174  0.325263   \n",
      "1        2       1   16              2  1  0.200624  0.099450  0.699926   \n",
      "2        3       3   15              1  1  0.333248  0.130143  0.536609   \n",
      "3        4       1   15              0  1  0.429973  0.147559  0.422469   \n",
      "4        5       2   12              0  0  0.529563  0.145174  0.325263   \n",
      "...    ...     ...  ...            ... ..       ...       ...       ...   \n",
      "2395  2396       1   13              1  1  0.447387  0.140431  0.412182   \n",
      "2396  2397       3   13              1  1  0.447387  0.140431  0.412182   \n",
      "2397  2398       1   13              0  1  0.544068  0.150073  0.305859   \n",
      "2398  2399       3   15              3  1  0.171511  0.086738  0.741751   \n",
      "2399  2400       2   15              4  1  0.115431  0.066431  0.818138   \n",
      "\n",
      "      Predicted  \n",
      "0             1  \n",
      "1             3  \n",
      "2             3  \n",
      "3             1  \n",
      "4             1  \n",
      "...         ...  \n",
      "2395          1  \n",
      "2396          1  \n",
      "2397          1  \n",
      "2398          3  \n",
      "2399          3  \n",
      "\n",
      "[2400 rows x 9 columns]\n"
     ]
    }
   ],
   "source": [
    "print(hsb2.drop(['SubVehID'],axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0607802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scipy in c:\\users\\admin\\anaconda3\\lib\\site-packages (1.11.1)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy<1.28.0,>=1.21.6 in c:\\users\\admin\\anaconda3\\lib\\site-packages (from scipy) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "pip install scipy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ca4fa92e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.01763632677883641",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_2464\\936316383.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mobserved_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChoice\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mexpected_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhsb2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPredicted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# Chi-Square Goodness of Fit Test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m chi_square_test_statistic, p_value = stats.chisquare( \n\u001b[0m\u001b[0;32m     12\u001b[0m     observed_data, expected_data) \n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;31m# chi square test statistic and p value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(f_obs, f_exp, ddof, axis)\u001b[0m\n\u001b[0;32m   8250\u001b[0m     ...           axis=1)\n\u001b[0;32m   8251\u001b[0m     \u001b[0mPower_divergenceResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstatistic\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m3.5\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;36m9.25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.62338763\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.09949846\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8252\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8253\u001b[0m     \"\"\"  # noqa\n\u001b[1;32m-> 8254\u001b[1;33m     return power_divergence(f_obs, f_exp=f_exp, ddof=ddof, axis=axis,\n\u001b[0m\u001b[0;32m   8255\u001b[0m                             lambda_=\"pearson\")\n",
      "\u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(f_obs, f_exp, ddof, axis, lambda_)\u001b[0m\n\u001b[0;32m   8047\u001b[0m                    \u001b[1;34mf\"frequencies must agree with the sum of the \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8048\u001b[0m                    \u001b[1;34mf\"expected frequencies to a relative tolerance \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8049\u001b[0m                    \u001b[1;34mf\"of {rtol}, but the percent differences are:\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8050\u001b[0m                    f\"{relative_diff}\")\n\u001b[1;32m-> 8051\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   8052\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8053\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   8054\u001b[0m         \u001b[1;31m# Ignore 'invalid' errors so the edge case of a data set with length 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.01763632677883641"
     ]
    }
   ],
   "source": [
    "# importing packages\n",
    "import scipy.stats as stats \n",
    "import numpy as np \n",
    "  \n",
    "# no of hours a student studies \n",
    "# in a week vs expected no of hours \n",
    "observed_data = hsb2.Choice\n",
    "expected_data = hsb2.Predicted \n",
    "  \n",
    "# Chi-Square Goodness of Fit Test \n",
    "chi_square_test_statistic, p_value = stats.chisquare( \n",
    "    observed_data, expected_data) \n",
    "  \n",
    "# chi square test statistic and p value \n",
    "print('chi_square_test_statistic is : ' +\n",
    "      str(chi_square_test_statistic))  # Corrected the print statement\n",
    "  \n",
    "# importing packages \n",
    "import scipy.stats as stats \n",
    "import numpy as np \n",
    "  \n",
    "# no of hours a student studies \n",
    "# in a week vs expected no of hours \n",
    "observed_data = hsb2.Choice\n",
    "expected_data = hsb2.Predicted \n",
    "  \n",
    "  \n",
    "# Chi-Square Goodness of Fit Test \n",
    "chi_square_test_statistic, p_value = stats.chisquare( \n",
    "    observed_data, expected_data) \n",
    "  \n",
    "# chi square test statistic and p value \n",
    "print('chi_square_test_statistic is : ' +\n",
    "      str(chi_square_test_statistic)) \n",
    "print('p_value : ' + str(p_value)) \n",
    "  \n",
    "  \n",
    "# find Chi-Square critical value \n",
    "print(stats.chi2.ppf(1-0.05, df=3))  # Corrected the print statement\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e0111ce6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(hsb2.Choice)-len(hsb2.Predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0e0aebae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      const  Gap  RelativeSpeed TW\n",
      "0       1.0   12              0  0\n",
      "1       1.0   16              2  1\n",
      "2       1.0   15              1  1\n",
      "3       1.0   15              0  1\n",
      "4       1.0   12              0  0\n",
      "...     ...  ...            ... ..\n",
      "2395    1.0   13              1  1\n",
      "2396    1.0   13              1  1\n",
      "2397    1.0   13              0  1\n",
      "2398    1.0   15              3  1\n",
      "2399    1.0   15              4  1\n",
      "\n",
      "[2400 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "X = sm.add_constant(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "52e2d34a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.863698\n",
      "         Iterations 6\n",
      "Optimization terminated successfully.\n",
      "         Current function value: 0.984104\n",
      "         Iterations 6\n",
      "Rho-squared:  0.1223504172765787\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "\n",
    "\n",
    "\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "\n",
    "\n",
    "# Fit the multinomial logistic regression model\n",
    "model = MNLogit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Get the log-likelihood of the fitted model\n",
    "log_likelihood_fitted = result.llf\n",
    "\n",
    "# Get the log-likelihood of the null model\n",
    "# Null model is the model with only the intercept\n",
    "X_null = sm.add_constant(pd.DataFrame({'intercept': np.ones(len(y))}))\n",
    "null_model = MNLogit(y, X_null)\n",
    "null_result = null_model.fit()\n",
    "log_likelihood_null = null_result.llf\n",
    "\n",
    "# Calculate the rho-squared statistic\n",
    "rho_squared = 1 - (log_likelihood_fitted / log_likelihood_null)\n",
    "print('Rho-squared: ', rho_squared)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5c9cd561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.863698\n",
      "         Iterations 6\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                 Choice   No. Observations:                 2400\n",
      "Model:                        MNLogit   Df Residuals:                     2392\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Thu, 06 Jun 2024   Pseudo R-squ.:                  0.1224\n",
      "Time:                        21:51:09   Log-Likelihood:                -2072.9\n",
      "converged:                       True   LL-Null:                       -2361.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.331e-121\n",
      "=================================================================================\n",
      "     Choice=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -2.6055      0.604     -4.311      0.000      -3.790      -1.421\n",
      "Gap               0.1093      0.040      2.726      0.006       0.031       0.188\n",
      "RelativeSpeed     0.1293      0.043      2.985      0.003       0.044       0.214\n",
      "TW               -0.1025      0.137     -0.747      0.455      -0.371       0.166\n",
      "---------------------------------------------------------------------------------\n",
      "     Choice=3       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -3.8349      0.469     -8.174      0.000      -4.754      -2.915\n",
      "Gap               0.2791      0.031      9.035      0.000       0.219       0.340\n",
      "RelativeSpeed     0.4945      0.036     13.565      0.000       0.423       0.566\n",
      "TW               -0.3703      0.104     -3.567      0.000      -0.574      -0.167\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Example dataset\n",
    "\n",
    "# Adding a constant to the model (intercept)\n",
    "X = sm.add_constant(X)\n",
    "\n",
    "# Fitting the MNLogit model\n",
    "model = sm.MNLogit(y, X)\n",
    "result = model.fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95c9d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(random_state=0, multi_class='multinomial', solver='newton-cg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ef3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
