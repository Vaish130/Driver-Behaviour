{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e90a4746",
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73b292bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URL read successfully\n"
     ]
    }
   ],
   "source": [
    "link = \"https://stats.idre.ucla.edu/stat/data/hsb2.csv\"\n",
    "webUrl = urllib.request.urlopen(link)\n",
    "if webUrl.getcode() == 200:\n",
    "    print(\"URL read successfully\")\n",
    "else:\n",
    "    print(\"URL not read successfully, check url link/internet connection and try again\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98220763",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = requests.get(link).content\n",
    "hsb2 = pd.read_csv(io.StringIO(s.decode('utf-8')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ad8134f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>female</th>\n",
       "      <th>race</th>\n",
       "      <th>ses</th>\n",
       "      <th>schtyp</th>\n",
       "      <th>prog</th>\n",
       "      <th>read</th>\n",
       "      <th>write</th>\n",
       "      <th>math</th>\n",
       "      <th>science</th>\n",
       "      <th>socst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  female  race  ses  schtyp  prog  read  write  math  science  socst\n",
       "0   70       0     4    1       1     1    57     52    41       47     57\n",
       "1  121       1     4    2       1     3    68     59    53       63     61\n",
       "2   86       0     4    3       1     1    44     33    54       58     31\n",
       "3  141       0     4    3       1     3    63     44    47       53     56\n",
       "4  172       0     4    2       1     2    47     52    57       53     61"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "464badf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id         int64\n",
       "female     int64\n",
       "race       int64\n",
       "ses        int64\n",
       "schtyp     int64\n",
       "prog       int64\n",
       "read       int64\n",
       "write      int64\n",
       "math       int64\n",
       "science    int64\n",
       "socst      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e86c0a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsb2[\"race\"] = hsb2[\"race\"].astype('category')\n",
    "hsb2[\"female\"] = hsb2[\"female\"].astype('category')\n",
    "hsb2[\"ses\"] = hsb2[\"ses\"].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "822346ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id            int64\n",
       "female     category\n",
       "race       category\n",
       "ses        category\n",
       "schtyp        int64\n",
       "prog          int64\n",
       "read          int64\n",
       "write         int64\n",
       "math          int64\n",
       "science       int64\n",
       "socst         int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0d84c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Assuming hsb2 is already defined as follows:\n",
    "# hsb2 = pd.read_csv(\"hsb2.csv\")\n",
    "\n",
    "# Convert categorical variables to dummy variables\n",
    "race = pd.get_dummies(hsb2['race'], drop_first=True, prefix='race')\n",
    "ses = pd.get_dummies(hsb2['ses'], drop_first=True, prefix='ses')\n",
    "female = pd.get_dummies(hsb2['female'], drop_first=True, prefix='female')\n",
    "\n",
    "# Drop original categorical columns and add the new dummy variables\n",
    "hsb3 = hsb2.drop(['race', 'ses', 'female'], axis=1)\n",
    "hsb3 = pd.concat([hsb3, race, ses, female], axis=1)\n",
    "\n",
    "hsb2[\"race_2\"] = hsb2[\"race\"].astype('int64')\n",
    "hsb2[\"ses_2\"] = hsb2[\"ses\"].astype('int64')\n",
    "hsb2[\"race_3\"] = hsb2[\"race\"].astype('int64')\n",
    "hsb2[\"ses_3\"] = hsb2[\"ses\"].astype('int64')\n",
    "hsb2[\"race_4\"] = hsb2[\"race\"].astype('int64')\n",
    "hsb2[\"female\"] = hsb2[\"female\"].astype('int64')\n",
    "\n",
    "\n",
    "# Define target variable and features\n",
    "y = (hsb3['prog'] - 1).astype(int)  # Adjusting the labels to start from 0 and converting to integer\n",
    "X = hsb3.drop(['prog', 'id'], axis=1)  # Convert features to numpy array\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9a2fd0a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>schtyp</th>\n",
       "      <th>read</th>\n",
       "      <th>write</th>\n",
       "      <th>math</th>\n",
       "      <th>science</th>\n",
       "      <th>socst</th>\n",
       "      <th>race_2</th>\n",
       "      <th>race_3</th>\n",
       "      <th>race_4</th>\n",
       "      <th>ses_2</th>\n",
       "      <th>ses_3</th>\n",
       "      <th>female_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   schtyp  read  write  math  science  socst  race_2  race_3  race_4  ses_2  \\\n",
       "0       1    57     52    41       47     57   False   False    True  False   \n",
       "1       1    68     59    53       63     61   False   False    True   True   \n",
       "2       1    44     33    54       58     31   False   False    True  False   \n",
       "3       1    63     44    47       53     56   False   False    True  False   \n",
       "4       1    47     52    57       53     61   False   False    True   True   \n",
       "\n",
       "   ses_3  female_1  \n",
       "0  False     False  \n",
       "1  False      True  \n",
       "2   True     False  \n",
       "3   True     False  \n",
       "4  False     False  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e1d9c7a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type float which has no callable exp method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'exp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 36\u001b[0m\n\u001b[0;32m     33\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y))\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m beta \u001b[38;5;241m=\u001b[39m fit_multinomial_logistic_regression(X\u001b[38;5;241m.\u001b[39mvalues, y\u001b[38;5;241m.\u001b[39mvalues, num_classes)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntercept and Coefficients:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(beta)\n",
      "Cell \u001b[1;32mIn[25], line 26\u001b[0m, in \u001b[0;36mfit_multinomial_logistic_regression\u001b[1;34m(X, y, num_classes, max_iter)\u001b[0m\n\u001b[0;32m     24\u001b[0m num_samples, num_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     25\u001b[0m initial_params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, num_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m---> 26\u001b[0m result \u001b[38;5;241m=\u001b[39m minimize(log_likelihood, initial_params, args\u001b[38;5;241m=\u001b[39m(X, y, num_classes),\n\u001b[0;32m     27\u001b[0m                   method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m'\u001b[39m, options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: max_iter})\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Add zero coefficients for the reference class to the result\u001b[39;00m\n\u001b[0;32m     29\u001b[0m beta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, num_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)), result\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mreshape(num_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, num_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    711\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:307\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[1;32m--> 307\u001b[0m sf \u001b[38;5;241m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[38;5;241m=\u001b[39mjac, args\u001b[38;5;241m=\u001b[39margs, epsilon\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    308\u001b[0m                               bounds\u001b[38;5;241m=\u001b[39mnew_bounds,\n\u001b[0;32m    309\u001b[0m                               finite_diff_rel_step\u001b[38;5;241m=\u001b[39mfinite_diff_rel_step)\n\u001b[0;32m    311\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[0;32m    313\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:383\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    379\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 383\u001b[0m sf \u001b[38;5;241m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0;32m    384\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[38;5;241m=\u001b[39mepsilon)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[1;32mIn[25], line 18\u001b[0m, in \u001b[0;36mlog_likelihood\u001b[1;34m(params, X, y, num_classes)\u001b[0m\n\u001b[0;32m     16\u001b[0m X_intercept \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39mones((num_samples, \u001b[38;5;241m1\u001b[39m)), X])  \u001b[38;5;66;03m# Add intercept term\u001b[39;00m\n\u001b[0;32m     17\u001b[0m logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_intercept, beta\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m---> 18\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m softmax(logits)\n\u001b[0;32m     19\u001b[0m ll \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(probabilities[np\u001b[38;5;241m.\u001b[39marange(num_samples), y]))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mll\n",
      "Cell \u001b[1;32mIn[25], line 7\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m      5\u001b[0m     z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape if z is a 1D array\u001b[39;00m\n\u001b[0;32m      6\u001b[0m z \u001b[38;5;241m=\u001b[39m z \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(z, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# For numerical stability\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m exp_z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(z)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m exp_z \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(exp_z, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type float which has no callable exp method"
     ]
    }
   ],
   "source": [
    "# Define the softmax function\n",
    "def softmax(z):\n",
    "    z = np.array(z)  # Ensure z is a numpy array\n",
    "    if z.ndim == 1:\n",
    "        z = z.reshape(1, -1)  # Reshape if z is a 1D array\n",
    "    z = z - np.max(z, axis=1, keepdims=True)  # For numerical stability\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "# Define the log-likelihood function\n",
    "def log_likelihood(params, X, y, num_classes):\n",
    "    num_samples, num_features = X.shape\n",
    "    # Reshape params and add zero coefficients for the reference class\n",
    "    params = params.reshape((num_classes - 1, num_features + 1))\n",
    "    beta = np.vstack([np.zeros((1, num_features + 1)), params])\n",
    "    X_intercept = np.hstack([np.ones((num_samples, 1)), X])  # Add intercept term\n",
    "    logits = np.dot(X_intercept, beta.T)\n",
    "    probabilities = softmax(logits)\n",
    "    ll = np.sum(np.log(probabilities[np.arange(num_samples), y]))\n",
    "    return -ll  # We negate because we will be minimizing\n",
    "\n",
    "# Fit the model\n",
    "def fit_multinomial_logistic_regression(X, y, num_classes, max_iter=100):\n",
    "    num_samples, num_features = X.shape\n",
    "    initial_params = np.zeros((num_classes - 1, num_features + 1)).ravel()\n",
    "    result = minimize(log_likelihood, initial_params, args=(X, y, num_classes),\n",
    "                      method='L-BFGS-B', options={'maxiter': max_iter})\n",
    "    # Add zero coefficients for the reference class to the result\n",
    "    beta = np.vstack([np.zeros((1, num_features + 1)), result.x.reshape(num_classes - 1, num_features + 1)])\n",
    "    return beta\n",
    "\n",
    "# Define the number of classes based on your dataset\n",
    "num_classes = len(np.unique(y))\n",
    "\n",
    "# Fit the model\n",
    "beta = fit_multinomial_logistic_regression(X.values, y.values, num_classes)\n",
    "\n",
    "print(\"Intercept and Coefficients:\")\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2049381d",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type float which has no callable exp method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'exp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[26], line 35\u001b[0m\n\u001b[0;32m     32\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(np\u001b[38;5;241m.\u001b[39munique(y))  \u001b[38;5;66;03m# Define the number of classes based on your dataset\u001b[39;00m\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 35\u001b[0m beta \u001b[38;5;241m=\u001b[39m fit_multinomial_logistic_regression(X, y, num_classes)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntercept and Coefficients:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(beta)\n",
      "Cell \u001b[1;32mIn[26], line 26\u001b[0m, in \u001b[0;36mfit_multinomial_logistic_regression\u001b[1;34m(X, y, num_classes, max_iter)\u001b[0m\n\u001b[0;32m     24\u001b[0m num_samples, num_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m     25\u001b[0m initial_params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, num_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mravel()\n\u001b[1;32m---> 26\u001b[0m result \u001b[38;5;241m=\u001b[39m minimize(log_likelihood, initial_params, args\u001b[38;5;241m=\u001b[39m(X, y, num_classes),\n\u001b[0;32m     27\u001b[0m                   method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m'\u001b[39m, options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: max_iter})\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Add zero coefficients for the reference class to the result\u001b[39;00m\n\u001b[0;32m     29\u001b[0m beta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvstack([np\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;241m1\u001b[39m, num_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)), result\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mreshape(num_classes \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m, num_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)])\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    711\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:307\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[1;32m--> 307\u001b[0m sf \u001b[38;5;241m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[38;5;241m=\u001b[39mjac, args\u001b[38;5;241m=\u001b[39margs, epsilon\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    308\u001b[0m                               bounds\u001b[38;5;241m=\u001b[39mnew_bounds,\n\u001b[0;32m    309\u001b[0m                               finite_diff_rel_step\u001b[38;5;241m=\u001b[39mfinite_diff_rel_step)\n\u001b[0;32m    311\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[0;32m    313\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:383\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    379\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 383\u001b[0m sf \u001b[38;5;241m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0;32m    384\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[38;5;241m=\u001b[39mepsilon)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[1;32mIn[26], line 18\u001b[0m, in \u001b[0;36mlog_likelihood\u001b[1;34m(params, X, y, num_classes)\u001b[0m\n\u001b[0;32m     16\u001b[0m X_intercept \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mhstack([np\u001b[38;5;241m.\u001b[39mones((num_samples, \u001b[38;5;241m1\u001b[39m)), X])  \u001b[38;5;66;03m# Add intercept term\u001b[39;00m\n\u001b[0;32m     17\u001b[0m logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_intercept, beta\u001b[38;5;241m.\u001b[39mT)\n\u001b[1;32m---> 18\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m softmax(logits)\n\u001b[0;32m     19\u001b[0m ll \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(probabilities[np\u001b[38;5;241m.\u001b[39marange(num_samples), y]))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mll\n",
      "Cell \u001b[1;32mIn[26], line 7\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m      5\u001b[0m     z \u001b[38;5;241m=\u001b[39m z\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# Reshape if z is a 1D array\u001b[39;00m\n\u001b[0;32m      6\u001b[0m z \u001b[38;5;241m=\u001b[39m z \u001b[38;5;241m-\u001b[39m np\u001b[38;5;241m.\u001b[39mmax(z, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# For numerical stability\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m exp_z \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(z)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m exp_z \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(exp_z, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type float which has no callable exp method"
     ]
    }
   ],
   "source": [
    "\n",
    "# Define the softmax function\n",
    "def softmax(z):\n",
    "    z = np.array(z)  # Ensure z is a numpy array\n",
    "    if z.ndim == 1:\n",
    "        z = z.reshape(1, -1)  # Reshape if z is a 1D array\n",
    "    z = z - np.max(z, axis=1, keepdims=True)  # For numerical stability\n",
    "    exp_z = np.exp(z)\n",
    "    return exp_z / np.sum(exp_z, axis=1, keepdims=True)\n",
    "\n",
    "# Define the log-likelihood function\n",
    "def log_likelihood(params, X, y, num_classes):\n",
    "    num_samples, num_features = X.shape\n",
    "    # Reshape params and add zero coefficients for the reference class\n",
    "    params = params.reshape((num_classes - 1, num_features + 1))\n",
    "    beta = np.vstack([np.zeros((1, num_features + 1)), params])\n",
    "    X_intercept = np.hstack([np.ones((num_samples, 1)), X])  # Add intercept term\n",
    "    logits = np.dot(X_intercept, beta.T)\n",
    "    probabilities = softmax(logits)\n",
    "    ll = np.sum(np.log(probabilities[np.arange(num_samples), y]))\n",
    "    return -ll  # We negate because we will be minimizing\n",
    "\n",
    "# Fit the model\n",
    "def fit_multinomial_logistic_regression(X, y, num_classes, max_iter=100):\n",
    "    num_samples, num_features = X.shape\n",
    "    initial_params = np.zeros((num_classes - 1, num_features + 1)).ravel()\n",
    "    result = minimize(log_likelihood, initial_params, args=(X, y, num_classes),\n",
    "                      method='L-BFGS-B', options={'maxiter': max_iter})\n",
    "    # Add zero coefficients for the reference class to the result\n",
    "    beta = np.vstack([np.zeros((1, num_features + 1)), result.x.reshape(num_classes - 1, num_features + 1)])\n",
    "    return beta\n",
    "\n",
    "num_classes = len(np.unique(y))  # Define the number of classes based on your dataset\n",
    "\n",
    "# Fit the model\n",
    "beta = fit_multinomial_logistic_regression(X, y, num_classes)\n",
    "\n",
    "print(\"Intercept and Coefficients:\")\n",
    "print(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b420e6b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>schtyp</th>\n",
       "      <th>prog</th>\n",
       "      <th>read</th>\n",
       "      <th>write</th>\n",
       "      <th>math</th>\n",
       "      <th>science</th>\n",
       "      <th>socst</th>\n",
       "      <th>race_2</th>\n",
       "      <th>race_3</th>\n",
       "      <th>race_4</th>\n",
       "      <th>ses_2</th>\n",
       "      <th>ses_3</th>\n",
       "      <th>female_1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>70</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>52</td>\n",
       "      <td>41</td>\n",
       "      <td>47</td>\n",
       "      <td>57</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>68</td>\n",
       "      <td>59</td>\n",
       "      <td>53</td>\n",
       "      <td>63</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>44</td>\n",
       "      <td>33</td>\n",
       "      <td>54</td>\n",
       "      <td>58</td>\n",
       "      <td>31</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>141</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>63</td>\n",
       "      <td>44</td>\n",
       "      <td>47</td>\n",
       "      <td>53</td>\n",
       "      <td>56</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>47</td>\n",
       "      <td>52</td>\n",
       "      <td>57</td>\n",
       "      <td>53</td>\n",
       "      <td>61</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  schtyp  prog  read  write  math  science  socst  race_2  race_3  \\\n",
       "0   70       1     1    57     52    41       47     57   False   False   \n",
       "1  121       1     3    68     59    53       63     61   False   False   \n",
       "2   86       1     1    44     33    54       58     31   False   False   \n",
       "3  141       1     3    63     44    47       53     56   False   False   \n",
       "4  172       1     2    47     52    57       53     61   False   False   \n",
       "\n",
       "   race_4  ses_2  ses_3  female_1  \n",
       "0    True  False  False     False  \n",
       "1    True   True  False      True  \n",
       "2    True  False   True     False  \n",
       "3    True  False   True     False  \n",
       "4    True   True  False     False  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hsb3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ffc4cc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200, 12)\n"
     ]
    }
   ],
   "source": [
    "y = hsb3['prog']\n",
    "X = hsb3.drop(['prog','id'],axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "394e9fd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "loop of ufunc does not support argument 0 of type float which has no callable exp method",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'exp'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 42\u001b[0m\n\u001b[0;32m     37\u001b[0m num_classes \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;66;03m# Fit the model\u001b[39;00m\n\u001b[1;32m---> 42\u001b[0m beta \u001b[38;5;241m=\u001b[39m fit_multinomial_logistic_regression(X, y, num_classes)\n\u001b[0;32m     45\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIntercept and Coefficients:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28mprint\u001b[39m(beta)\n",
      "Cell \u001b[1;32mIn[11], line 30\u001b[0m, in \u001b[0;36mfit_multinomial_logistic_regression\u001b[1;34m(X, y, num_classes, max_iter)\u001b[0m\n\u001b[0;32m     28\u001b[0m initial_params \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros((num_classes, num_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mravel()\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Optimize the log-likelihood function\u001b[39;00m\n\u001b[1;32m---> 30\u001b[0m result \u001b[38;5;241m=\u001b[39m minimize(log_likelihood, initial_params, args\u001b[38;5;241m=\u001b[39m(X, y, num_classes),\n\u001b[0;32m     31\u001b[0m                   method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m'\u001b[39m, options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m: max_iter})\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Reshape the result into the coefficient matrix\u001b[39;00m\n\u001b[0;32m     33\u001b[0m beta \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39mx\u001b[38;5;241m.\u001b[39mreshape(num_classes, num_features \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_minimize.py:710\u001b[0m, in \u001b[0;36mminimize\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    707\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    708\u001b[0m                              \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    709\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124ml-bfgs-b\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 710\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0;32m    711\u001b[0m                            callback\u001b[38;5;241m=\u001b[39mcallback, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[0;32m    712\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtnc\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    713\u001b[0m     res \u001b[38;5;241m=\u001b[39m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[38;5;241m=\u001b[39mcallback,\n\u001b[0;32m    714\u001b[0m                         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py:307\u001b[0m, in \u001b[0;36m_minimize_lbfgsb\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    304\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    305\u001b[0m         iprint \u001b[38;5;241m=\u001b[39m disp\n\u001b[1;32m--> 307\u001b[0m sf \u001b[38;5;241m=\u001b[39m _prepare_scalar_function(fun, x0, jac\u001b[38;5;241m=\u001b[39mjac, args\u001b[38;5;241m=\u001b[39margs, epsilon\u001b[38;5;241m=\u001b[39meps,\n\u001b[0;32m    308\u001b[0m                               bounds\u001b[38;5;241m=\u001b[39mnew_bounds,\n\u001b[0;32m    309\u001b[0m                               finite_diff_rel_step\u001b[38;5;241m=\u001b[39mfinite_diff_rel_step)\n\u001b[0;32m    311\u001b[0m func_and_grad \u001b[38;5;241m=\u001b[39m sf\u001b[38;5;241m.\u001b[39mfun_and_grad\n\u001b[0;32m    313\u001b[0m fortran_int \u001b[38;5;241m=\u001b[39m _lbfgsb\u001b[38;5;241m.\u001b[39mtypes\u001b[38;5;241m.\u001b[39mintvar\u001b[38;5;241m.\u001b[39mdtype\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_optimize.py:383\u001b[0m, in \u001b[0;36m_prepare_scalar_function\u001b[1;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[0;32m    379\u001b[0m     bounds \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, np\u001b[38;5;241m.\u001b[39minf)\n\u001b[0;32m    381\u001b[0m \u001b[38;5;66;03m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[39;00m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;66;03m# calculation reduces overall function evaluations.\u001b[39;00m\n\u001b[1;32m--> 383\u001b[0m sf \u001b[38;5;241m=\u001b[39m ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0;32m    384\u001b[0m                     finite_diff_rel_step, bounds, epsilon\u001b[38;5;241m=\u001b[39mepsilon)\n\u001b[0;32m    386\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sf\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:158\u001b[0m, in \u001b[0;36mScalarFunction.__init__\u001b[1;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl \u001b[38;5;241m=\u001b[39m update_fun\n\u001b[1;32m--> 158\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun()\n\u001b[0;32m    160\u001b[0m \u001b[38;5;66;03m# Gradient evaluation\u001b[39;00m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(grad):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:251\u001b[0m, in \u001b[0;36mScalarFunction._update_fun\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_update_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    250\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated:\n\u001b[1;32m--> 251\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_fun_impl()\n\u001b[0;32m    252\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf_updated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:155\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.update_fun\u001b[1;34m()\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mupdate_fun\u001b[39m():\n\u001b[1;32m--> 155\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mf \u001b[38;5;241m=\u001b[39m fun_wrapped(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py:137\u001b[0m, in \u001b[0;36mScalarFunction.__init__.<locals>.fun_wrapped\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnfev \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    134\u001b[0m \u001b[38;5;66;03m# Send a copy because the user may overwrite it.\u001b[39;00m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;66;03m# Overwriting results in undefined behaviour because\u001b[39;00m\n\u001b[0;32m    136\u001b[0m \u001b[38;5;66;03m# fun(self.x) will change self.x, with the two no longer linked.\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m fx \u001b[38;5;241m=\u001b[39m fun(np\u001b[38;5;241m.\u001b[39mcopy(x), \u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# Make sure the function returns a true scalar\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m np\u001b[38;5;241m.\u001b[39misscalar(fx):\n",
      "Cell \u001b[1;32mIn[11], line 19\u001b[0m, in \u001b[0;36mlog_likelihood\u001b[1;34m(params, X, y, num_classes)\u001b[0m\n\u001b[0;32m     17\u001b[0m logits \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(X_intercept, beta\u001b[38;5;241m.\u001b[39mT)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Compute the probabilities using the softmax function\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m probabilities \u001b[38;5;241m=\u001b[39m softmax(logits)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Compute the log-likelihood\u001b[39;00m\n\u001b[0;32m     21\u001b[0m ll \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(probabilities[np\u001b[38;5;241m.\u001b[39marange(num_samples), y]))\n",
      "Cell \u001b[1;32mIn[11], line 6\u001b[0m, in \u001b[0;36msoftmax\u001b[1;34m(z)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msoftmax\u001b[39m(z):\n\u001b[1;32m----> 6\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mexp(z) \u001b[38;5;241m/\u001b[39m np\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mexp(z), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: loop of ufunc does not support argument 0 of type float which has no callable exp method"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "# Define the softmax function\n",
    "def softmax(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "\n",
    "# Define the log-likelihood function\n",
    "def log_likelihood(params, X, y, num_classes):\n",
    "    num_samples, num_features = X.shape\n",
    "    # Reshape the parameter array into a coefficient matrix\n",
    "    beta = params.reshape(num_classes, num_features + 1)\n",
    "    # Add a column of ones for the intercept term\n",
    "    X_intercept = np.hstack([np.ones((num_samples, 1)), X])\n",
    "    \n",
    "    # Compute the linear combination\n",
    "    logits = np.dot(X_intercept, beta.T)\n",
    "    # Compute the probabilities using the softmax function\n",
    "    probabilities = softmax(logits)\n",
    "    # Compute the log-likelihood\n",
    "    ll = np.sum(np.log(probabilities[np.arange(num_samples), y]))\n",
    "    return -ll  # Return the negative log-likelihood for minimization\n",
    "\n",
    "# Define a function to fit the model\n",
    "def fit_multinomial_logistic_regression(X, y, num_classes, max_iter=1000000):\n",
    "    num_samples, num_features = X.shape\n",
    "    # Initialize parameters\n",
    "    initial_params = np.zeros((num_classes, num_features + 1)).ravel()\n",
    "    # Optimize the log-likelihood function\n",
    "    result = minimize(log_likelihood, initial_params, args=(X, y, num_classes),\n",
    "                      method='L-BFGS-B', options={'maxiter': max_iter})\n",
    "    # Reshape the result into the coefficient matrix\n",
    "    beta = result.x.reshape(num_classes, num_features + 1)\n",
    "    return beta\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "beta = fit_multinomial_logistic_regression(X, y, num_classes)\n",
    "\n",
    "\n",
    "print(\"Intercept and Coefficients:\")\n",
    "print(beta)\n",
    "\n",
    "ll_model=-log_likelihood(beta, X, y, num_classes)\n",
    "print(ll_model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59c709c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4625c39",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "60f34a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Accuracy: 0.605 (0.076)\n"
     ]
    }
   ],
   "source": [
    "# define the multinomial logistic regression model with a default penalty\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', \n",
    "                           C=1.0, max_iter = 1000000)\n",
    "# define the model evaluation procedure\n",
    "cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "# evaluate the model and collect the scores\n",
    "n_scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "# report the model performance\n",
    "print('Mean Accuracy: %.3f (%.3f)' % (mean(n_scores), std(n_scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "21ec1842",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e63f304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Probabilities: [0.41802658 0.38916056 0.19281286]\n"
     ]
    }
   ],
   "source": [
    "row = X.iloc[0:1, :]\n",
    "# predict a multinomial probability distribution\n",
    "yhat = model.predict_proba(row)\n",
    "# summarize the predicted probabilities\n",
    "print('Predicted Probabilities: %s' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45b5bbc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Class: 1\n"
     ]
    }
   ],
   "source": [
    "# predict the class label\n",
    "yhat = model.predict(row)\n",
    "# summarize the predicted class\n",
    "print('Predicted Class: %d' % yhat[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0607802b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.0000 0.557 (0.090)\n",
      ">0.0001 0.610 (0.072)\n",
      ">0.0010 0.592 (0.074)\n",
      ">0.0100 0.587 (0.087)\n",
      ">0.1000 0.542 (0.101)\n",
      ">1.0000 0.560 (0.086)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# get a list of models to evaluate\n",
    "def get_models():\n",
    "\tmodels = dict()\n",
    "\tfor p in [0.0, 0.0001, 0.001, 0.01, 0.1, 1.0]:\n",
    "\t\t# create name for model\n",
    "\t\tkey = '%.4f' % p\n",
    "\t\t# turn off penalty in some cases\n",
    "\t\tif p == 0.0:\n",
    "\t\t\t# no penalty in this case\n",
    "\t\t\tmodels[key] = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='none')\n",
    "\t\telse:\n",
    "\t\t\tmodels[key] = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', C=p)\n",
    "\treturn models\n",
    "# evaluate a give model using cross-validation\n",
    "def evaluate_model(model, X, y):\n",
    "\t# define the evaluation procedure\n",
    "\tcv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "\t# evaluate the model\n",
    "\tscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "\treturn scores\n",
    "# get the models to evaluate\n",
    "models = get_models()\n",
    "# evaluate the models and store results\n",
    "results, names = list(), list()\n",
    "for name, model in models.items():\n",
    "\t# evaluate the model and collect the scores\n",
    "\tscores = evaluate_model(model, X, y)\n",
    "\t# store the results\n",
    "\tresults.append(scores)\n",
    "\tnames.append(name)\n",
    "\t# summarize progress along the way\n",
    "\tprint('>%s %.3f (%.3f)' % (name, mean(scores), std(scores)))\n",
    "# plot model performance for comparison\n",
    "pyplot.boxplot(results, labels=names, showmeans=True)\n",
    "pyplot.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "16d283b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.03499999 -5.26312933  5.29812932]\n",
      "dvimvdfikgmfb\n",
      "[[-0.01853798  0.12456048 -0.01750114 -0.00941341 -0.03176713  0.04841889\n",
      "   0.00951909  0.81697744  0.12838444  0.16347083 -0.47413961 -0.49836098]\n",
      " [-0.13411336  0.69420737  0.02571986  0.02229972  0.07277303 -0.05093159\n",
      "   0.03257294 -0.35029337 -0.11432353 -0.29302308 -0.22382163  0.36072192]\n",
      " [ 0.15265134 -0.81876785 -0.00821872 -0.01288631 -0.0410059   0.0025127\n",
      "  -0.04209203 -0.46668407 -0.0140609   0.12955226  0.69796124  0.13763906]]\n"
     ]
    }
   ],
   "source": [
    "print(result.intercept_)\n",
    "print(\"dvimvdfikgmfb\")\n",
    "print(result.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "405144eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = pd.DataFrame(zip(X.columns, np.transpose(result.coef_.tolist()[0])), \n",
    "                       columns=['features', 'coef'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f91d55f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   features      coef\n",
      "0    female -0.018538\n",
      "1    schtyp  0.124560\n",
      "2      read -0.017501\n",
      "3     write -0.009413\n",
      "4      math -0.031767\n",
      "5   science  0.048419\n",
      "6     socst  0.009519\n",
      "7    race_2  0.816977\n",
      "8    race_3  0.128384\n",
      "9    race_4  0.163471\n",
      "10    ses_2 -0.474140\n",
      "11    ses_3 -0.498361\n"
     ]
    }
   ],
   "source": [
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0111ce6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
