{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e90a4746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>SubVehID</th>\n",
       "      <th>Choice</th>\n",
       "      <th>Gap</th>\n",
       "      <th>RelativeSpeed</th>\n",
       "      <th>TW</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  SubVehID  Choice  Gap  RelativeSpeed TW\n",
       "0   1         9       1   12              0  0\n",
       "1   2        13       0   16              2  1\n",
       "2   3        13       2   15              1  1\n",
       "3   4        13       0   15              0  1\n",
       "4   5        36       1   12              0  0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import requests\n",
    "import io\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot\n",
    "from statsmodels.discrete.discrete_model import MNLogit\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "hsb2 = pd.read_csv(\"C:\\\\Users\\\\Admin\\\\Desktop\\\\Vaishnavi\\\\Auto\\\\DriverData1.csv\")\n",
    "\n",
    "hsb2[\"Gap\"] = hsb2[\"Gap\"].astype('int64')\n",
    "hsb2[\"RelativeSpeed\"] = hsb2[\"RelativeSpeed\"].astype('int64')\n",
    "hsb2[\"TW\"] = hsb2[\"TW\"].astype('category')\n",
    "hsb2['Choice']=hsb2['Choice']-1\n",
    "\n",
    "hsb3 = hsb2\n",
    "hsb3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "98220763",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = hsb3['Choice']\n",
    "X = hsb3.drop(['ID','SubVehID','Choice'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc4cc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "765e4439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept: [ 2.14744897 -0.45742293 -1.69002604]\n",
      "Coefficients: [[-0.12946688 -0.20774494  0.15692087]\n",
      " [-0.02023765 -0.07849998  0.0538605 ]\n",
      " [ 0.14970453  0.28624493 -0.21078137]]\n",
      " \n",
      "Rho-squared: 0.12235023609532403\n",
      "Chi-square statistic: 577.9456458256163\n",
      "p-value: 9.184486612176098e-124\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from scipy import stats\n",
    "from sklearn.metrics import log_loss\n",
    "# Create a multinomial logistic regression model\n",
    "\n",
    "\n",
    "model =LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', \n",
    "                           C=1.0, max_iter=1000000)\n",
    "\n",
    "# Fit the model to the data\n",
    "model.fit(X, y)\n",
    "print(\"Intercept:\",model.intercept_)\n",
    "print(\"Coefficients:\",model.coef_)\n",
    "\n",
    "\n",
    "\n",
    "# Get the log-likelihood of the fitted model\n",
    "y_prob = model.predict_proba(X)\n",
    "LL_model = -log_loss(y, y_prob, normalize=False)\n",
    "\n",
    "# Fit the null model (only an intercept)\n",
    "null_model = LogisticRegression(multi_class='multinomial', solver='lbfgs', penalty='l2', \n",
    "                                C=1.0, max_iter=1000000, fit_intercept=True)\n",
    "X_null = np.ones((X.shape[0], 1))  # Only intercept\n",
    "null_model.fit(X_null, y)\n",
    "\n",
    "# Get the log-likelihood of the null model\n",
    "y_null_prob = null_model.predict_proba(X_null)\n",
    "LL_null = -log_loss(y, y_null_prob, normalize=False)\n",
    "\n",
    "\n",
    "chi_square_stat = 2 * (LL_model - LL_null)\n",
    "df_model = X.shape[1] * (len(np.unique(y)) - 1) \n",
    "df_null = len(np.unique(y)) - 1  # Number of intercepts in the null model\n",
    "df_diff = df_model - df_null\n",
    "p_value = stats.chi2.sf(chi_square_stat, df_diff)\n",
    "rho_squared = 1 - (LL_model / LL_null)\n",
    "print(\" \")\n",
    "print(\"Rho-squared:\", rho_squared)\n",
    "print(\"Chi-square statistic:\", chi_square_stat)\n",
    "print(\"p-value:\", p_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6f10615",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "c = []\n",
    "# Initialize an empty list to store predicted probabilities\n",
    "for i in range(len(hsb2.ID)):\n",
    "    row = X.iloc[i:i+1, :]  # Select a single row from the DataFrame\n",
    "    # Predict a multinomial probability distribution\n",
    "    yhat = model.predict(row)\n",
    "    # Summarize the predicted probabilities and append to the list\n",
    "    c.append(yhat[0])\n",
    "    \n",
    "\n",
    "hsb2['Predicted'] = c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a9994efa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400, 3)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4a0a8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20864e4f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (2400,) (2400,3) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 31\u001b[0m\n\u001b[0;32m     28\u001b[0m num_features \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     29\u001b[0m beta \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mrandn(num_features, num_classes)\n\u001b[1;32m---> 31\u001b[0m ll \u001b[38;5;241m=\u001b[39m log_likelihood(X, y, beta)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLog Likelihood:\u001b[39m\u001b[38;5;124m\"\u001b[39m, ll)\n",
      "Cell \u001b[1;32mIn[5], line 19\u001b[0m, in \u001b[0;36mlog_likelihood\u001b[1;34m(X, y, beta)\u001b[0m\n\u001b[0;32m     16\u001b[0m eXB \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexp(W)\n\u001b[0;32m     17\u001b[0m eXB \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m eXB\u001b[38;5;241m.\u001b[39msum(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)[:, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m---> 19\u001b[0m log_likelihood_value \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(y \u001b[38;5;241m*\u001b[39m np\u001b[38;5;241m.\u001b[39mlog(eXB))\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m log_likelihood_value\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\common.py:81\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[0;32m     79\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[1;32m---> 81\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;28mself\u001b[39m, other)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\arraylike.py:202\u001b[0m, in \u001b[0;36mOpsMixin.__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__mul__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_arith_method(other, operator\u001b[38;5;241m.\u001b[39mmul)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:6112\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   6110\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[0;32m   6111\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39malign_method_SERIES(\u001b[38;5;28mself\u001b[39m, other)\n\u001b[1;32m-> 6112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m base\u001b[38;5;241m.\u001b[39mIndexOpsMixin\u001b[38;5;241m.\u001b[39m_arith_method(\u001b[38;5;28mself\u001b[39m, other, op)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:1348\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[1;34m(self, other, op)\u001b[0m\n\u001b[0;32m   1345\u001b[0m rvalues \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(rvalues)\n\u001b[0;32m   1347\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m-> 1348\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m   1350\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_construct_result(result, name\u001b[38;5;241m=\u001b[39mres_name)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:232\u001b[0m, in \u001b[0;36marithmetic_op\u001b[1;34m(left, right, op)\u001b[0m\n\u001b[0;32m    228\u001b[0m     _bool_arith_check(op, left, right)\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;66;03m# error: Argument 1 to \"_na_arithmetic_op\" has incompatible type\u001b[39;00m\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;66;03m# \"Union[ExtensionArray, ndarray[Any, Any]]\"; expected \"ndarray[Any, Any]\"\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m     res_values \u001b[38;5;241m=\u001b[39m _na_arithmetic_op(left, right, op)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m    234\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res_values\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\ops\\array_ops.py:171\u001b[0m, in \u001b[0;36m_na_arithmetic_op\u001b[1;34m(left, right, op, is_cmp)\u001b[0m\n\u001b[0;32m    168\u001b[0m     func \u001b[38;5;241m=\u001b[39m partial(expressions\u001b[38;5;241m.\u001b[39mevaluate, op)\n\u001b[0;32m    170\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 171\u001b[0m     result \u001b[38;5;241m=\u001b[39m func(left, right)\n\u001b[0;32m    172\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m    173\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_cmp \u001b[38;5;129;01mand\u001b[39;00m (is_object_dtype(left\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mor\u001b[39;00m is_object_dtype(right)):\n\u001b[0;32m    174\u001b[0m         \u001b[38;5;66;03m# For object dtype, fallback to a masked operation (only operating\u001b[39;00m\n\u001b[0;32m    175\u001b[0m         \u001b[38;5;66;03m#  on the non-missing values)\u001b[39;00m\n\u001b[0;32m    176\u001b[0m         \u001b[38;5;66;03m# Don't do this for comparisons, as that will handle complex numbers\u001b[39;00m\n\u001b[0;32m    177\u001b[0m         \u001b[38;5;66;03m#  incorrectly, see GH#32047\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:239\u001b[0m, in \u001b[0;36mevaluate\u001b[1;34m(op, a, b, use_numexpr)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m op_str \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    237\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m use_numexpr:\n\u001b[0;32m    238\u001b[0m         \u001b[38;5;66;03m# error: \"None\" not callable\u001b[39;00m\n\u001b[1;32m--> 239\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate(op, op_str, a, b)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _evaluate_standard(op, op_str, a, b)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:128\u001b[0m, in \u001b[0;36m_evaluate_numexpr\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m    125\u001b[0m     _store_test_result(result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    127\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 128\u001b[0m     result \u001b[38;5;241m=\u001b[39m _evaluate_standard(op, op_str, a, b)\n\u001b[0;32m    130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\computation\\expressions.py:70\u001b[0m, in \u001b[0;36m_evaluate_standard\u001b[1;34m(op, op_str, a, b)\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _TEST_MODE:\n\u001b[0;32m     69\u001b[0m     _store_test_result(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op(a, b)\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (2400,) (2400,3) "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def log_likelihood(X, y, beta):\n",
    "    \"\"\"\n",
    "    Calculate the log likelihood for multinomial logistic regression.\n",
    "    \n",
    "    Args:\n",
    "        X (numpy.ndarray): Design matrix (shape: N x M), where N is the number of samples and M is the number of features.\n",
    "        y (numpy.ndarray): Target labels (shape: N x 1), where each label corresponds to a class (0, 1, ..., K-1).\n",
    "        beta (numpy.ndarray): Model coefficients (shape: M x K), where K is the number of classes.\n",
    "    \n",
    "    Returns:\n",
    "        float: Log likelihood value.\n",
    "    \"\"\"\n",
    "    W = np.dot(X, beta)\n",
    "    eXB = np.exp(W)\n",
    "    eXB /= eXB.sum(axis=1)[:, None]\n",
    "    \n",
    "    log_likelihood_value = np.sum(y * np.log(eXB))\n",
    "    return log_likelihood_value\n",
    "\n",
    "# Example usage:\n",
    "# Assuming you have X (design matrix), y (target labels), and beta (model coefficients)\n",
    "# log_likelihood_value = log_likelihood(X, y, beta)\n",
    "# print(f\"Log Likelihood: {log_likelihood_value:.4f}\")\n",
    "# Initialize theta with correct shape\n",
    "num_classes = 3  # Assuming 3 classes\n",
    "num_features = X.shape[1]\n",
    "beta = np.random.randn(num_features, num_classes)\n",
    "\n",
    "ll = log_likelihood(X, y, beta)\n",
    "print(\"Log Likelihood:\", ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f18ebe45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.19730665  0.51714549  0.5896668 ]\n",
      " [-0.98319007 -0.38771223 -1.16472142]\n",
      " [-1.12652781 -1.28837583 -1.49074854]]\n",
      "[[6.31705842e-03 2.93336300e-01 7.00346641e-01]\n",
      " [1.37844694e-03 6.43863377e-01 3.54758176e-01]\n",
      " [2.52232779e-03 4.71724258e-01 5.25753414e-01]\n",
      " ...\n",
      " [5.90272631e-03 3.21009664e-01 6.73087610e-01]\n",
      " [1.31351750e-03 8.08254314e-01 1.90432169e-01]\n",
      " [8.07710612e-04 9.01531063e-01 9.76612262e-02]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Compute the softmax of each row of the input array z.\n",
    "    \n",
    "    Parameters:\n",
    "    z (ndarray): Input array of shape (n, k) where n is the number of samples and k is the number of classes.\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: Output array of the same shape as z where each row is the softmax of the corresponding row of z.\n",
    "    \"\"\"\n",
    "      # Subtract max for numerical stability\n",
    "    a=np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "    print(a)\n",
    "    return a\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Initialize theta with correct shape\n",
    "num_classes = 3  # Assuming 3 classes\n",
    "num_features = X.shape[1]\n",
    "theta = np.random.randn(num_features, num_classes)\n",
    "print(theta)\n",
    "\n",
    "\n",
    "ll = softmax(np.dot(X, theta))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39bd4eb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.02077279  1.19874199  0.83724988 -0.17549782]\n",
      " [ 1.47433424 -1.53466741  0.56597923  1.55306486]\n",
      " [-1.01193267  0.54309464 -0.65625141 -0.13848144]]\n",
      "-39217.464098503384\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "\n",
    "\n",
    "def softmax(z):\n",
    "    \"\"\"\n",
    "    Compute the softmax of each row of the input array z.\n",
    "    \n",
    "    Parameters:\n",
    "    z (ndarray): Input array of shape (n, k) where n is the number of samples and k is the number of classes.\n",
    "    \n",
    "    Returns:\n",
    "    ndarray: Output array of the same shape as z where each row is the softmax of the corresponding row of z.\n",
    "    \"\"\"\n",
    "      # Subtract max for numerical stability\n",
    "    a=np.exp(z) / np.sum(np.exp(z), axis=1, keepdims=True)\n",
    "    return a\n",
    "\n",
    "def log_likelihood(params, X, y, num_classes):\n",
    "    \n",
    "    # Reshape the parameter array into a coefficient matrix\n",
    "    beta = params.reshape(num_classes, num_features + 1)\n",
    "    # Add a column of ones for the intercept term\n",
    "   \n",
    "    \n",
    "    # Compute the linear combination\n",
    "    logits = np.dot(X, beta.T)\n",
    "    # Compute the probabilities using the softmax function\n",
    "    probabilities = softmax(logits)\n",
    "    # Compute the log-likelihood\n",
    "    log_likelihood = np.sum(np.log(probabilities[np.arange(num_samples), y]))\n",
    "    return -log_likelihood  # Return the negative log-likelihood for minimization\n",
    "\n",
    "\n",
    "num_classes = 3  # Assuming 3 classes\n",
    "num_samples, num_features = X.shape\n",
    "theta = np.random.randn(num_features, num_classes)\n",
    "X_intercept = np.hstack([np.ones((num_samples, 1)), X])\n",
    "print(theta)\n",
    "X_null = np.ones((X.shape[0], 3))  # Only intercept\n",
    "\n",
    "ll = log_likelihood_multinomial_logistic(X, y, theta)\n",
    "print(ll)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75a1deb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bc5b0bca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Likelihood: -17244.615875651383\n",
      "Null Log Likelihood: -4017.108143319909\n",
      " \n",
      "Rho-squared: -3.292793537143787\n",
      "Chi-square statistic: -26455.01546466295\n",
      "p-value: 1.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import chi2\n",
    "\n",
    "def softmax(logits):\n",
    "    \"\"\"\n",
    "    Compute the softmax for a set of logits.\n",
    "\n",
    "    Parameters:\n",
    "    logits (np.ndarray): An array of logits with shape (n_samples, n_classes).\n",
    "\n",
    "    Returns:\n",
    "    np.ndarray: An array of probabilities with the same shape as logits.\n",
    "    \"\"\"\n",
    "    # Subtract the max logits to prevent overflow issues\n",
    "    exp_logits = np.exp(logits - np.max(logits, axis=1, keepdims=True))\n",
    "    # Calculate softmax by dividing the exponentiated logits by the sum of exponentiated logits for each sample\n",
    "    probabilities = exp_logits / np.sum(exp_logits, axis=1, keepdims=True)\n",
    "    return probabilities\n",
    "\n",
    "def log_likelihood_multinomial_logistic(X, y, theta):\n",
    "    \"\"\"\n",
    "    Calculate the log likelihood of the data given a multinomial logistic regression model.\n",
    "    \n",
    "    Parameters:\n",
    "    X (ndarray): Input feature matrix of shape (n, d).\n",
    "    y (ndarray): True class labels of shape (n,).\n",
    "    theta (ndarray): Model parameters of shape (d, k).\n",
    "    \n",
    "    Returns:\n",
    "    float: Log likelihood value.\n",
    "    \"\"\"\n",
    "    n, d = X.shape\n",
    "    k = theta.shape[1]\n",
    "    \n",
    "    # Compute the linear combination\n",
    "    linear_combination = np.dot(X, theta)\n",
    "    \n",
    "    # Compute the softmax probabilities\n",
    "    probabilities = softmax(linear_combination)\n",
    "    \n",
    "    # Create a one-hot encoded matrix of the true labels\n",
    "    y_one_hot = np.zeros((n, k))\n",
    "    y_one_hot[np.arange(n), y] = 1\n",
    "    \n",
    "    # Compute the log likelihood\n",
    "    log_likelihood = np.sum(y_one_hot * np.log(probabilities))\n",
    "    \n",
    "    return log_likelihood\n",
    "\n",
    "# Example usage\n",
    "\n",
    "\n",
    "# Initialize theta with correct shape\n",
    "num_classes = 3  # Assuming 3 classes\n",
    "num_features = X.shape[1]\n",
    "theta = np.random.randn(num_features, num_classes)\n",
    "\n",
    "X_null = np.ones((X.shape[0], 3))  # Only intercept\n",
    "\n",
    "ll = log_likelihood_multinomial_logistic(X, y, theta)\n",
    "print(\"Log Likelihood:\", ll)\n",
    "\n",
    "null_ll = log_likelihood_multinomial_logistic(X_null, y, theta)\n",
    "print(\"Null Log Likelihood:\", null_ll)\n",
    "\n",
    "chi_square_stat = 2 * (ll - null_ll)\n",
    "\n",
    "df_model = X.shape[1] * (len(np.unique(y)) - 1) \n",
    "df_null = len(np.unique(y)) - 1  # Number of intercepts in the null model\n",
    "df_diff = df_model - df_null\n",
    "p_value = stats.chi2.sf(chi_square_stat, df_diff)\n",
    "rho_squared = 1 - (ll / null_ll)\n",
    "print(\" \")\n",
    "print(\"Rho-squared:\", rho_squared)\n",
    "print(\"Chi-square statistic:\", chi_square_stat)\n",
    "print(\"p-value:\", p_value)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82e48560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc1748d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d945d946",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b80b4cd0",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block after function definition on line 6 (3100923982.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[11], line 10\u001b[1;36m\u001b[0m\n\u001b[1;33m    def log_likelihood(params, X, y, num_classes):\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block after function definition on line 6\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from scipy.special import softmax\n",
    "\n",
    "# Define the softmax function\n",
    "def softmax(z):\n",
    "\n",
    "\n",
    "# Define the log-likelihood function\n",
    "def log_likelihood(params, X, y, num_classes):\n",
    "    num_samples, num_features = X.shape\n",
    "    # Reshape the parameter array into a coefficient matrix\n",
    "    beta = params.reshape(num_classes, num_features + 1)\n",
    "    # Add a column of ones for the intercept term\n",
    "    X_intercept = np.hstack([np.ones((num_samples, 1)), X])\n",
    "    \n",
    "    # Compute the linear combination\n",
    "    logits = np.dot(X_intercept, beta.T)\n",
    "    # Compute the probabilities using the softmax function\n",
    "    probabilities = softmax(logits)\n",
    "    # Compute the log-likelihood\n",
    "    log_likelihood = np.sum(np.log(probabilities[np.arange(num_samples), y]))\n",
    "    return -log_likelihood  # Return the negative log-likelihood for minimization\n",
    "\n",
    "# Define a function to fit the model\n",
    "def fit_multinomial_logistic_regression(X, y, num_classes, max_iter=1000000):\n",
    "    num_samples, num_features = X.shape\n",
    "    # Initialize parameters\n",
    "    initial_params = np.zeros((num_classes, num_features + 1)).ravel()\n",
    "    # Optimize the log-likelihood function\n",
    "    result = minimize(log_likelihood, initial_params, args=(X, y, num_classes),\n",
    "                      method='L-BFGS-B', options={'maxiter': max_iter})\n",
    "    # Reshape the result into the coefficient matrix\n",
    "    beta = result.x.reshape(num_classes, num_features + 1)\n",
    "    return beta\n",
    "\n",
    "\n",
    "num_classes = 3\n",
    "\n",
    "# Subtract 1 from y to ensure class labels start from 0\n",
    "\n",
    "\n",
    "# Fit the model\n",
    "beta = fit_multinomial_logistic_regression(X, y, num_classes)\n",
    "\n",
    "\n",
    "print(\"Intercept and Coefficients:\")\n",
    "print(beta)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d579a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to predict probabilities\n",
    "def predict_probabilities(X, beta):\n",
    "    X_intercept = np.hstack([np.ones((X.shape[0], 1)), X])\n",
    "    logits = np.dot(X_intercept, beta.T)\n",
    "    probabilities = softmax(logits)\n",
    "    return probabilities\n",
    "\n",
    "# Predict probabilities and class labels\n",
    "c = []\n",
    "y_pred = []\n",
    "\n",
    "for i in range(len(hsb2)):\n",
    "    row = X.iloc[i:i+1, :]  # Select a single row from the DataFrame\n",
    "    # Predict a multinomial probability distribution\n",
    "    phat = predict_probabilities(row, beta)\n",
    "    # Summarize the predicted probabilities and append to the list\n",
    "    c.append(phat[0])\n",
    "    # Determine the predicted class label (the one with the highest probability)\n",
    "    y_pred.append(np.argmax(phat))\n",
    "hsb2['Predicted_1'] = y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fa99a5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f58b6de",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49846f07",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "db50098f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.863698\n",
      "         Iterations 6\n",
      "                          MNLogit Regression Results                          \n",
      "==============================================================================\n",
      "Dep. Variable:                 Choice   No. Observations:                 2400\n",
      "Model:                        MNLogit   Df Residuals:                     2392\n",
      "Method:                           MLE   Df Model:                            6\n",
      "Date:                Thu, 13 Jun 2024   Pseudo R-squ.:                  0.1224\n",
      "Time:                        12:00:50   Log-Likelihood:                -2072.9\n",
      "converged:                       True   LL-Null:                       -2361.8\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.331e-121\n",
      "=================================================================================\n",
      "     Choice=1       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -2.6055      0.604     -4.311      0.000      -3.790      -1.421\n",
      "Gap               0.1093      0.040      2.726      0.006       0.031       0.188\n",
      "RelativeSpeed     0.1293      0.043      2.985      0.003       0.044       0.214\n",
      "TW               -0.1025      0.137     -0.747      0.455      -0.371       0.166\n",
      "---------------------------------------------------------------------------------\n",
      "     Choice=2       coef    std err          z      P>|z|      [0.025      0.975]\n",
      "---------------------------------------------------------------------------------\n",
      "const            -3.8349      0.469     -8.174      0.000      -4.754      -2.915\n",
      "Gap               0.2791      0.031      9.035      0.000       0.219       0.340\n",
      "RelativeSpeed     0.4945      0.036     13.565      0.000       0.423       0.566\n",
      "TW               -0.3703      0.104     -3.567      0.000      -0.574      -0.167\n",
      "=================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Fitting the MNLogit model\n",
    "X1 = sm.add_constant(X)\n",
    "\n",
    "model = sm.MNLogit(y, X1)\n",
    "result = model.fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eaefebd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict probabilities\n",
    "pred_probs = result.predict(X1)\n",
    "\n",
    "# Predict the class with the highest probability\n",
    "y_pred = np.argmax(pred_probs.values, axis=1)\n",
    "\n",
    "# Add predictions to the dataframe\n",
    "hsb2['Predicted_Class'] = y_pred\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "99f09aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "hsb2.to_csv(\"Results.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c4cd66aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " ...\n",
      " [1. 0. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "n, d = X.shape\n",
    "k = theta.shape[1]\n",
    "    \n",
    "\n",
    "    \n",
    "    # Create a one-hot encoded matrix of the true labels\n",
    "y_one_hot = np.zeros((n, k))\n",
    "y_one_hot[np.arange(n), y] = 1\n",
    "print(y_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6635d468",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                  int64\n",
       "SubVehID            int64\n",
       "Choice              int64\n",
       "Gap                 int64\n",
       "RelativeSpeed       int64\n",
       "TW               category\n",
       "dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d54489d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
